services:
  dt_base:
    image: dt_base
    build:
      context: .
      dockerfile: docker/base.Dockerfile

  dt_base_python:
    image: dt_base_python
    build:
      context: .
      dockerfile: docker/base_python.Dockerfile
    depends_on:
      - dt_base

  dt_web: &dt_web
    init: true
    container_name: dt_web
    build:
      context: .
      dockerfile: docker/web.Dockerfile
    env_file:
      - '.env'
    volumes:
      - .:/home/app/web:z
      - ./docker/volumes/web/:/_project_volume/
      - ${HOME}/.aws:/nonexistent/.aws
    ports:
      - '8000:8000'
      - '5678:5678' # debugging
      - '5679:5679' # debugging tests
      - '8001:8001' # jupyter notebook

    depends_on:
      - dt_base_python
      - dt_db
      - dt_redis
    command: python manage.py runserver 0.0.0.0:8000

  dt_celery:
    <<: *dt_web
    container_name: dt_celery
    ports: [ ]
    env_file:
      - '.env'
    command: python3 -m celery -A dt worker --loglevel INFO --pidfile /tmp/celery.pid

  dt_flower:
    <<: *dt_web
    container_name: dt_flower
    env_file:
      - '.env'
    ports:
      - "5555:5555"
    command: python3 -m celery -A dt flower --url_prefix=flower --persistent=True --loglevel INFO --pidfile /tmp/flower.pid --db="/tmp/flower.db"

  dt_db:
    init: true
    image: postgres:14-alpine
    container_name: dt_db
    volumes:
      - ./docker/volumes/db_active/:/var/lib/postgresql/data:z
      - ./docker/volumes/db/:/_project_volume/
    ports:
      # if env var HOST_POSTGRES_PORT is defined, will expose on host machine
      # for easily connecting with external tools
      - ${POSTGRES_PORT:-5432}

    env_file:
      - '.env'
    command:
      [ 'postgres', '-c', 'log_statement=all', '-c', 'log_destination=stderr' ,'-c','shared_buffers=1GB','-c', 'work_mem=128MB']

  dt_redis:
    init: true
    image: redis
    container_name: dt_redis
